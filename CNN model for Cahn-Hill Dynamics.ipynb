{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you can install PyFFTW for speed-up as - \n",
      "conda install -c conda-forge pyfftw\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tqdm\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import chnet.cahn_hill as ch\n",
    "import chnet.ch_tools as tools\n",
    "import utilities as utils\n",
    "import torch.nn.functional as F\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, utils\n",
    "from toolz.curried import pipe, curry, compose\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [8.0, 6.0]\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['legend.fontsize'] = 'large'\n",
    "mpl.rcParams['figure.titlesize'] = 'medium'\n",
    "\n",
    "def draw_im(im, title=None):\n",
    "    im = np.squeeze(im)\n",
    "    plt.imshow(im)\n",
    "    plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "@curry\n",
    "def return_slice(x_data, cutoff):\n",
    "    if cutoff is not None:\n",
    "        return pipe(x_data,\n",
    "                    lambda x_data: np.asarray(x_data.shape).astype(int) // 2,\n",
    "                    lambda new_shape: [slice(new_shape[idim]-cutoff,\n",
    "                                             new_shape[idim]+cutoff+1)\n",
    "                                       for idim in range(x_data.ndim)],\n",
    "                    lambda slices: x_data[slices])\n",
    "    else:\n",
    "        return x_data\n",
    "    \n",
    "cropper = return_slice(cutoff=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_unif(nsamples, dim_x, dim_y, seed=354875):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.uniform(-0.95, 0.95, size=(nsamples, dim_x, dim_y))\n",
    "\n",
    "\n",
    "def init_norm(nsamples, dim_x, dim_y, seed=354875):\n",
    "    np.random.seed(seed)\n",
    "    means  = np.random.uniform(-0.1, 0.1, size=nsamples)\n",
    "    scales  = np.random.uniform(0.1, 0.5, size=nsamples)\n",
    "    \n",
    "    x_data = [np.random.normal(loc=m, scale=s, size = (1, dim_x, dim_y)) for m,s in zip(means, scales)]\n",
    "    x_data = np.concatenate(x_data, axis=0)\n",
    "    \n",
    "    np.clip(x_data, -0.95, 0.95, out=x_data)\n",
    "    \n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y1, y2, scale=1.):\n",
    "    \"\"\"standard MSE definition\"\"\"\n",
    "    assert y1.shape == y2.shape\n",
    "    return ((y1 - y2) ** 2).sum() / y1.data.nelement() * scale\n",
    "\n",
    "@curry\n",
    "def rmse_loss(y1, y2, scale=1.):\n",
    "    \"\"\"standard RMSE definition\"\"\"\n",
    "    assert y1.shape == y2.shape\n",
    "    return ((((y1 - y2) ** 2).sum() / y1.data.nelement()).sqrt()) * scale\n",
    "\n",
    "\n",
    "def mse_loss_npy(y1, y2):\n",
    "    \"\"\"standard MSE definition\"\"\"\n",
    "    assert y1.shape == y2.shape\n",
    "    return np.sum(((y1 - y2) ** 2)) / y1.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1200 # no. of samples\n",
    "dim_x = 101\n",
    "dim_y = dim_x\n",
    "sim_steps = 600 # simulation steps\n",
    "dx = 0.25 # delta space_dim\n",
    "dt = 0.01 # delta time\n",
    "gamma = 1.0 # interface energy\n",
    "device = torch.device(\"cuda:0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_data1 = init_unif(nsamples//2, dim_x, dim_y, seed=354875)\n",
    "init_data2 = init_norm(nsamples//2, dim_x, dim_y, seed=982632)\n",
    "init_data = np.concatenate([init_data1, init_data2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_data = ch.ch_run_torch(init_data, dt=dt, gamma=gamma, dx=dx, sim_step=sim_steps, device=device)\n",
    "y_data = ch.ch_run_torch(x_data, dt=dt, gamma=gamma, dx=dx, sim_step=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "init_data1 = init_unif(250, dim_x, dim_y, seed=438645)\n",
    "init_data2 = init_norm(250, dim_x, dim_y, seed=234580)\n",
    "init_data = np.concatenate([init_data1, init_data2], axis=0)\n",
    "x_val = ch.ch_run_torch(init_data, dt=dt, gamma=gamma, dx=dx, sim_step=sim_steps, device=device)\n",
    "y_val = ch.ch_run_torch(x_val, dt=dt, gamma=gamma, dx=dx, sim_step=100, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chnet.ch_net import CHnet\n",
    "from chnet.ch_loader import CahnHillDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "ks = 5 # kernel size\n",
    "in_channels = 1 # no. of input channels\n",
    "cw = 64 # channel width\n",
    "model = CHnet(ks=ks, in_channels=in_channels, cw=cw).double().to(device)\n",
    "lx = (ks // 2) * 5 \n",
    "transformer_x = compose(lambda x: x[None], \n",
    "                        lambda x: np.pad(x, pad_width=[[lx,lx],[lx,lx]], mode='wrap'))\n",
    "\n",
    "transformer_y = lambda x: x[None]\n",
    "\n",
    "dataset = CahnHillDataset(x_data, y_data, transform_x=transformer_x, transform_y=transformer_y)\n",
    "\n",
    "item = dataset[0]\n",
    "x = item[\"x\"][None].to(device)\n",
    "y = item[\"y\"][None].to(device)\n",
    "\n",
    "\n",
    "\n",
    "item = dataset[0]\n",
    "x = item[\"x\"][None].to(device)\n",
    "y = item[\"y\"][None].to(device)\n",
    "y_pred = model(x)\n",
    "\n",
    "assert y.shape == y_pred.shape\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "print(mse_loss(y, y_pred).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprod = 0\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.size())\n",
    "    nprod += np.prod(parameter.size())\n",
    "print(\"No. of Parameters: %d\" % nprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@curry\n",
    "def add_neighbors(x):\n",
    "    dimx = x.shape[0]\n",
    "    y = np.pad(x, pad_width=[[2,2],[2,2]], mode=\"wrap\")\n",
    "    out = [x[None]]\n",
    "    for ix in [0, 1, 2, 3, 4]:\n",
    "        for iy in [0, 1, 2, 3, 4]:\n",
    "            out.append((y[ix:ix+dimx, iy:iy+dimx] * x)[None])\n",
    "    return np.concatenate(out, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimx = 5\n",
    "x_data = pipe(dimx, \n",
    "              lambda x: np.arange(1, x**2+1), \n",
    "              lambda x: np.reshape(x, (dimx, dimx)))\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = 5 # kernel size\n",
    "in_channels = 26 # no. of input channels\n",
    "cw = 32 # channel width\n",
    "\n",
    "train_batch_size = 2\n",
    "val_batch_size = 2\n",
    "\n",
    "transformer_x = compose(lambda x: add_neighbors(x), \n",
    "                        lambda x: np.pad(x, pad_width=[[lx,lx],[lx,lx]], mode='wrap'))\n",
    "\n",
    "transformer_y = lambda x: x[None]\n",
    "\n",
    "train_dataset = CahnHillDataset(x_data, y_data, transform_x=transformer_x, transform_y=transformer_y)\n",
    "trainloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "val_dataset = CahnHillDataset(x_val, y_val, transform_x=transformer_x, transform_y=transformer_y)\n",
    "valloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "total_step = len(trainloader)\n",
    "print(\"No. of training steps: %d\" % total_step)\n",
    "total_val_step = len(valloader)\n",
    "print(\"No. of validation steps: %d\" % total_val_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CHnet(ks=ks, in_channels=in_channels, cw=cw).double().to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "criterion = mse_loss\n",
    "learning_rate = 5e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "for epoch in range(num_epochs):    \n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(model.state_dict(), \"weights/CH_trial_1_%d\" % (epoch))\n",
    "                   \n",
    "    for i, item in enumerate(tqdm.tqdm_notebook(trainloader)):\n",
    "        model.train()\n",
    "        \n",
    "        x = item['x'].to(device)\n",
    "        target = item['y'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(x)\n",
    "        loss = criterion(output*100, target*100)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(np.sqrt(loss.item()))\n",
    "        \n",
    "        if (i) % 100 == 0:\n",
    "            for indx in np.random.permutation(np.arange(0, len(val_dataset)))[:5]:\n",
    "                model.eval()\n",
    "                item1 = val_dataset[indx]\n",
    "                x1 = item1['x'][None].to(device)\n",
    "                y1 = item1['y'][None].to(device)\n",
    "                # Forward pass\n",
    "                y2 = model(x1)\n",
    "                val_losses.append(np.sqrt(criterion(y2, y1).item()))\n",
    "                    \n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Training Loss: {:.11f}, Validation Loss: {:.11f}'.format(epoch+1, \n",
    "                                                                                                          num_epochs, \n",
    "                                                                                                          i+1, \n",
    "                                                                                                          total_step, \n",
    "                                                                                                          np.mean(train_losses[-50:]), \n",
    "                                                                                                          np.mean(val_losses[-5:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.title(\"training losses\")\n",
    "plt.xlabel(\"training steps\")\n",
    "plt.ylabel(\"mean squared error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses[100:])\n",
    "plt.title(\"training losses\")\n",
    "plt.xlabel(\"training steps\")\n",
    "plt.ylabel(\"mean squared error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_losses[100:])\n",
    "plt.title(\"Validation losses\")\n",
    "plt.xlabel(\"validation steps\")\n",
    "plt.ylabel(\"mean squared error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "item1 = val_dataset[indx]\n",
    "x1 = item1['x'][None].to(device)\n",
    "y1 = item1['y'][None].to(device)\n",
    "# Forward pass\n",
    "y2 = model(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_im(y1.detach().cpu().numpy(), \"Ground Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_im(y2.detach().cpu().numpy(), \"CNN output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_im(y1.detach().cpu().numpy() - y2.detach().cpu().numpy(), \"diff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

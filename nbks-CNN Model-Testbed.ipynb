{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from toolz.curried import pipe, curry, compose\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import chnet.ch_tools as ch_tools\n",
    "import chnet.utilities as ch_utils\n",
    "import chnet.ch_generator as ch_gen\n",
    "from chnet.ch_loader import CahnHillDataset\n",
    "from chnet.models import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(key=\"unet\", \n",
    "          ngf=32,\n",
    "          tanh=True,\n",
    "          mid=0.0, \n",
    "          dif=0.449, \n",
    "          dim_x=96, \n",
    "          dx=0.25, \n",
    "          dt=0.01, \n",
    "          gamma=0.2, \n",
    "          init_steps=1, \n",
    "          nstep=5, \n",
    "          n_samples_trn=1024, \n",
    "          n_datasets=10, \n",
    "          final_tstep=1001, \n",
    "          num_epochs=10, \n",
    "          learning_rate=1.0e-5,\n",
    "          optimizer=\"sgd\", \n",
    "          criterion=\"mae\",\n",
    "          scale=100,\n",
    "          device=\"cuda\", \n",
    "          save=True, \n",
    "          tag=\"script\", \n",
    "          fldr=\"weights\"):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\") if device == \"cuda\" else torch.device(\"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    model = get_model(key=key, ngf=ngf, tanh=tanh, nstep=nstep, device=device)\n",
    "    \n",
    "    delta_sim_steps=(final_tstep-init_steps)//nstep\n",
    "    primes = ch_utils.get_primes(50000)[:n_datasets]\n",
    "    print(\"no. of datasets: {}\".format(len(primes)))\n",
    "    fout = \"{}/model_{}_size_{}_step_{}_init_{}_delta_{}_tstep_{}_tanh_{}_loss_{}_tag_{}.pt\".format(fldr, key, ngf, nstep, init_steps, delta_sim_steps, num_epochs*len(primes), tanh, criterion, tag)  \n",
    "    print(\"model saved at: {}\".format(fout))\n",
    "\n",
    "    print(\"Start Training\")\n",
    "    trn_losses = []\n",
    "    criterion= get_criterion(criterion=criterion, scale=scale)\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(criterion)\n",
    "    print(optimizer)\n",
    "    for num, prime in enumerate(primes):\n",
    "        # Loss and optimizer\n",
    "        torch.cuda.empty_cache()\n",
    "        x_trn, y_trn = ch_gen.data_generator(nsamples=n_samples_trn, \n",
    "                                      dim_x=dim_x, \n",
    "                                      init_steps=init_steps, \n",
    "                                      delta_sim_steps = delta_sim_steps,\n",
    "                                      dx=dx, \n",
    "                                      dt=dt,\n",
    "                                      m_l=mid-dif, \n",
    "                                      m_r=mid+dif,\n",
    "                                      n_step=nstep,\n",
    "                                      gamma=gamma, \n",
    "                                      seed=2513*prime,\n",
    "                                      device=device)\n",
    "\n",
    "\n",
    "        trn_dataset = CahnHillDataset(x_trn, y_trn, \n",
    "                                      transform_x=lambda x: x[:,None], \n",
    "                                      transform_y=lambda x: x[:,None])\n",
    "\n",
    "        trn_loader = DataLoader(trn_dataset, \n",
    "                                batch_size=8, \n",
    "                                shuffle=True, \n",
    "                                num_workers=4)\n",
    "\n",
    "        print(\"Training Run: {}\".format(num+1))\n",
    "\n",
    "        total_step = len(trn_loader)\n",
    "        \n",
    "        for epoch in range(num_epochs):  \n",
    "            for i, item_trn in enumerate(tqdm(trn_loader)):\n",
    "                \n",
    "                model.train()\n",
    "                \n",
    "                if \"loop\" in key:\n",
    "                    if \"solo\" in key:\n",
    "                        x = item_trn['x'][:,0].to(device)\n",
    "                    else:\n",
    "                        x = item_trn['x'][:,0].to(device)\n",
    "                    y_tru = item_trn['y'].to(device)\n",
    "                else:\n",
    "                    x = item_trn['x'][:,0].to(device)\n",
    "                    y_tru = item_trn['y'][:,-1] .to(device) \n",
    "  \n",
    "                y_prd = model(x)# Forward pass\n",
    "                # means_inp = x.mean(axis=(1,2,3))\n",
    "                # means_out = y_prd.mean(axis=(1,2,3))\n",
    "                loss = criterion(y_tru, y_prd)\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                trn_losses.append(np.sqrt(loss.item()))\n",
    "\n",
    "            print ('Epoch [{}/{}], Training Loss: {:.11f}'.format(epoch+1, num_epochs, np.mean(trn_losses[-total_step:])))\n",
    "            # print (\"Means, inp: {:1.3f}, out: {:1.3f}\".format(x.mean(axis=(1,2,3)).data, y_prd.mean(axis=(1,2,3))).data)\n",
    "            obj = {}\n",
    "            obj[\"state\"] = model.state_dict()\n",
    "            obj[\"losses\"] = trn_losses\n",
    "            if save:\n",
    "                torch.save(obj, fout)\n",
    "    print(\"End Training\")\n",
    "    return obj\n",
    "\n",
    "def validate(key=\"unet\", \n",
    "              ngf=32,\n",
    "              tanh=True,\n",
    "              conv=True,\n",
    "              mid=0.0, \n",
    "              dif=0.449, \n",
    "              dim_x=96, \n",
    "              dx=0.25, \n",
    "              dt=0.01, \n",
    "              gamma=0.2, \n",
    "              nstep=20,\n",
    "              init_steps=1, \n",
    "              n_samples=1024, \n",
    "              final_tstep=5000, \n",
    "              seed=8634132, \n",
    "              device=\"cuda\", \n",
    "              weight_file=\"\",\n",
    "              vis=True):\n",
    "    \n",
    "    from chnet.ssim import SSIM\n",
    "    from chnet.mssim import MSSSIM\n",
    "    ssim_loss = SSIM(window_size=11)\n",
    "    mssim_loss = MSSSIM(window_size=11, channel=1) \n",
    "    mae_loss_npy = lambda x1, x2: np.mean(np.fabs(x1-x2))\n",
    "    \n",
    "    device = torch.device(\"cuda:0\") if device == \"cuda\" else torch.device(\"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    model = get_model(key=key, ngf=ngf, tanh=tanh, nstep=nstep, conv=conv, device=device)\n",
    "    model.load_state_dict(torch.load(weight_file, map_location=device)[\"state\"])\n",
    "\n",
    "    print(\"Start Validation\")\n",
    "    torch.cuda.empty_cache()\n",
    "    x_val, y_val = ch_gen.data_generator(nsamples=n_samples, \n",
    "                                  dim_x=dim_x, \n",
    "                                  init_steps=init_steps, \n",
    "                                  delta_sim_steps = (final_tstep-init_steps)//nstep,\n",
    "                                  dx=dx, \n",
    "                                  dt=dt,\n",
    "                                  m_l=mid-dif, \n",
    "                                  m_r=mid+dif,\n",
    "                                  n_step=nstep,\n",
    "                                  gamma=gamma, \n",
    "                                  seed=seed,\n",
    "                                  device=device)\n",
    "    \n",
    "    val_dataset = CahnHillDataset(x_val, y_val, \n",
    "                                  transform_x=lambda x: x[:,None], \n",
    "                                  transform_y=lambda x: x[:,None])\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    \n",
    "    errs = []\n",
    "    for ix in tqdm(range(len(val_dataset))):\n",
    "\n",
    "        item_v = val_dataset[ix]\n",
    "\n",
    "        x = item_v['x'][None][:,0].double().to(device)\n",
    "        y_tru = item_v['y'][None][:,-1].double().to(device) \n",
    "\n",
    "        if \"loop\" in key:\n",
    "            y_prd=model(x)[:,-1]\n",
    "        else:\n",
    "            y_prd=model(x)\n",
    "        im_x = x[0,0].detach().cpu().numpy()\n",
    "        im_y1 = y_tru[0,0].detach().cpu().numpy()\n",
    "        im_y2 = y_prd[0,0].detach().cpu().numpy()\n",
    "        errs.append(mae_loss_npy(im_y1, im_y2))\n",
    "\n",
    "        if vis:\n",
    "            if ((ix+1) % (n_samples//5)) == 0:\n",
    "                ch_utils.draw_by_side([im_x, im_y1, im_y2], \n",
    "                                      sub_titles=[\"inp\", \"sim\", \"cnn\"], \n",
    "                                      scale=8, vmin=None, vmax=None)\n",
    "                \n",
    "                \n",
    "                print(\"{:1.3f}, {:1.3f}, {:1.3f}\".format(ssim_loss(y_tru, x).item(), \n",
    "                      ssim_loss(y_tru, y_tru).item(), \n",
    "                      ssim_loss(y_tru, y_prd).item()))\n",
    "                \n",
    "                print(\"{:1.3f}, {:1.3f}, {:1.3f}\".format(mssim_loss(y_tru.float(), x.float()).item(), \n",
    "                      mssim_loss(y_tru.float(), y_tru.float()).item(), \n",
    "                      mssim_loss(y_tru.float(), y_prd.float()).item()))\n",
    "    return errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@curry\n",
    "def mse_loss(y1, y2, scale=1.):\n",
    "    \"\"\"standard MSE definition\"\"\"\n",
    "    return ((y1 - y2) ** 2).sum() / y1.data.nelement() * scale\n",
    "\n",
    "@curry\n",
    "def mae_loss(y1, y2, scale=1.):\n",
    "    \"\"\"standard MAE definition\"\"\"\n",
    "    return (torch.abs(y1 - y2)).sum() / y1.data.nelement() * scale\n",
    "\n",
    "\n",
    "@curry\n",
    "def ssim_loss(y1, y2, scale=11):\n",
    "    from pytorch_ssim import SSIM\n",
    "    ssim = SSIM(window_size=scale, size_average=True)\n",
    "    return 1. - 0.5 * ssim(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "no. of datasets: 5\n",
      "model saved at: weights/model_unet_size_32_step_2_init_101_delta_200_tstep_25_tanh_False_tag_jnbk_ssim13.pt\n",
      "Start Training\n",
      "Training Run: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338cb7e1d6344b139bb7c7aa8294d69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/5], Training Loss: 0.97293197353\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8168653f44ce4ede8b638e64f2c5f3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/5], Training Loss: 0.92828625812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484e32fb266545868dc2f763cd6d821d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/5], Training Loss: 0.90279005541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c02d505e654839bf9643ea05345c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/5], Training Loss: 0.89756930118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062a5e11716245409664c30cbde4f28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/5], Training Loss: 0.88270582208\n",
      "Training Run: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff63634e0364e178c81743bbc21875d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/5], Training Loss: 0.87436310842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0b3f39521f4cfcbb7275dfc030cce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/5], Training Loss: 0.86930140594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae09110ae7364c00b0eab72c52308439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/5], Training Loss: 0.86264845730\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e06a2e673cd45a5acd89412de4b2a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/5], Training Loss: 0.85756668626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49684ebccd3948cd888ea88ca0566008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/5], Training Loss: 0.85593930894\n",
      "Training Run: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a489bb173a436baa6df2aef7aac83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/5], Training Loss: 0.85318745240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2996f01c7244707abd6b4d51ae2057e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/5], Training Loss: 0.84705152770\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd4979f67c14311b51359b4e69b0cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/5], Training Loss: 0.84369811609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19288fa61b7d4208aa0a5600021d163f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/5], Training Loss: 0.83388035231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9945b60c2e4f45b866119533df484f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/5], Training Loss: 0.82983705843\n",
      "Training Run: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8541a195454b459b8273e84ea1cecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/5], Training Loss: 0.82619466723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6462a654d04c41149d8063bc5fae2701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/5], Training Loss: 0.82364848610\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cae8df60b24fddb89f39f48bff0f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/5], Training Loss: 0.81680103447\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee528fc31ed4887aa7f01d9ff5589ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/5], Training Loss: 0.81725524462\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204d0cae03404b86874c36677be4bcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/5], Training Loss: 0.81487793386\n",
      "Training Run: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0bac416230471ca0dd871882d655d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/5], Training Loss: 0.81635644252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db5cc5e83fa4a25b15d62b4fe07f602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/5], Training Loss: 0.81659552626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0bcfca2c10424c8ce9cd58db70af19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/5], Training Loss: 0.81003154484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631a6fc859bc44ba82384bb1e8f7894d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/5], Training Loss: 0.80585671305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c6bd191bef4c31a4df7257fb4139bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/5], Training Loss: 0.80485255899\n",
      "End Training\n"
     ]
    }
   ],
   "source": [
    "# obj = train(key=\"unet\", \n",
    "#             ngf=32, \n",
    "#             mid=0.0, \n",
    "#             dif=0.449, \n",
    "#             dim_x=96, \n",
    "#             dx=0.25, \n",
    "#             dt=0.01, \n",
    "#             gamma=0.2, \n",
    "#             n_samples_trn=1024,  \n",
    "#             nstep=2, \n",
    "#             init_steps=101, \n",
    "#             final_tstep=501, \n",
    "#             num_epochs=5, \n",
    "#             n_datasets=5, \n",
    "#             learning_rate=1e-05, \n",
    "#             device=\"cuda\", \n",
    "#             save=True,\n",
    "#             tanh=False,\n",
    "#             criterion=ssim_loss(scale=13),\n",
    "#             tag=\"jnbk_ssim13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UNet:\n\tsize mismatch for encoder1.enc1conv1.weight: copying a param with shape torch.Size([128, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 1, 3, 3]).\n\tsize mismatch for encoder1.enc1norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for encoder1.enc1norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder2.enc2conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for encoder2.enc2norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder2.enc2norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder3.enc3conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for encoder3.enc3norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder3.enc3norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder4.enc4conv1.weight: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for encoder4.enc4norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4conv2.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for encoder4.enc4norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for bottleneck.bottleneckconv1.weight: copying a param with shape torch.Size([2048, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3, 3]).\n\tsize mismatch for bottleneck.bottlenecknorm1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottleneckconv2.weight: copying a param with shape torch.Size([2048, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for bottleneck.bottlenecknorm2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for upconv4.weight: copying a param with shape torch.Size([2048, 1024, 2, 2]) from checkpoint, the shape in current model is torch.Size([1024, 512, 2, 2]).\n\tsize mismatch for upconv4.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4conv1.weight: copying a param with shape torch.Size([1024, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3, 3]).\n\tsize mismatch for decoder4.dec4norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4conv2.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for decoder4.dec4norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for upconv3.weight: copying a param with shape torch.Size([1024, 512, 2, 2]) from checkpoint, the shape in current model is torch.Size([512, 256, 2, 2]).\n\tsize mismatch for upconv3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3conv1.weight: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\n\tsize mismatch for decoder3.dec3norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for decoder3.dec3norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for upconv2.weight: copying a param with shape torch.Size([512, 256, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 128, 2, 2]).\n\tsize mismatch for upconv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\n\tsize mismatch for decoder2.dec2norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for decoder2.dec2norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for upconv1.weight: copying a param with shape torch.Size([256, 128, 2, 2]) from checkpoint, the shape in current model is torch.Size([128, 64, 2, 2]).\n\tsize mismatch for upconv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for decoder1.dec1norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for decoder1.dec1norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv.1.weight: copying a param with shape torch.Size([1, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0e2aa353d03c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8634132\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 weight_file=weight_file)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MAE mean: {:1.3f}, std: {:1.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-375f62a96864>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(key, ngf, tanh, conv, mid, dif, dim_x, dx, dt, gamma, nstep, init_steps, n_samples, final_tstep, seed, device, weight_file, vis)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mngf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start Validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/chnet/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 845\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNet:\n\tsize mismatch for encoder1.enc1conv1.weight: copying a param with shape torch.Size([128, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 1, 3, 3]).\n\tsize mismatch for encoder1.enc1norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for encoder1.enc1norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder1.enc1norm2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for encoder2.enc2conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for encoder2.enc2norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for encoder2.enc2norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder2.enc2norm2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for encoder3.enc3conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for encoder3.enc3norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for encoder3.enc3norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder3.enc3norm2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for encoder4.enc4conv1.weight: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for encoder4.enc4norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4conv2.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for encoder4.enc4norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder4.enc4norm2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for bottleneck.bottleneckconv1.weight: copying a param with shape torch.Size([2048, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3, 3]).\n\tsize mismatch for bottleneck.bottlenecknorm1.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm1.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm1.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm1.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottleneckconv2.weight: copying a param with shape torch.Size([2048, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3, 3]).\n\tsize mismatch for bottleneck.bottlenecknorm2.weight: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm2.bias: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm2.running_mean: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for bottleneck.bottlenecknorm2.running_var: copying a param with shape torch.Size([2048]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for upconv4.weight: copying a param with shape torch.Size([2048, 1024, 2, 2]) from checkpoint, the shape in current model is torch.Size([1024, 512, 2, 2]).\n\tsize mismatch for upconv4.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4conv1.weight: copying a param with shape torch.Size([1024, 2048, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 3, 3]).\n\tsize mismatch for decoder4.dec4norm1.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm1.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm1.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4conv2.weight: copying a param with shape torch.Size([1024, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for decoder4.dec4norm2.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm2.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm2.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder4.dec4norm2.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for upconv3.weight: copying a param with shape torch.Size([1024, 512, 2, 2]) from checkpoint, the shape in current model is torch.Size([512, 256, 2, 2]).\n\tsize mismatch for upconv3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3conv1.weight: copying a param with shape torch.Size([512, 1024, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 3, 3]).\n\tsize mismatch for decoder3.dec3norm1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for decoder3.dec3norm2.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm2.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for decoder3.dec3norm2.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for upconv2.weight: copying a param with shape torch.Size([512, 256, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 128, 2, 2]).\n\tsize mismatch for upconv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2conv1.weight: copying a param with shape torch.Size([256, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 3, 3]).\n\tsize mismatch for decoder2.dec2norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2conv2.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for decoder2.dec2norm2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for decoder2.dec2norm2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for upconv1.weight: copying a param with shape torch.Size([256, 128, 2, 2]) from checkpoint, the shape in current model is torch.Size([128, 64, 2, 2]).\n\tsize mismatch for upconv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for decoder1.dec1norm1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for decoder1.dec1norm2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for decoder1.dec1norm2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for conv.1.weight: copying a param with shape torch.Size([1, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 64, 3, 3])."
     ]
    }
   ],
   "source": [
    "weight_file=\"weights/model_unet_size_128_step_2_init_1_delta_2500_tstep_300_tanh_True_loss_mae_tag_testbed.pt\"\n",
    "errs = validate(key=\"unet\", \n",
    "                ngf=64,\n",
    "                tanh=True,\n",
    "                conv=True,\n",
    "                mid=0.0, \n",
    "                dif=0.449, \n",
    "                dim_x=96,\n",
    "                dx=0.25, \n",
    "                dt=0.01, \n",
    "                gamma=0.2, \n",
    "                n_samples=1024, \n",
    "                nstep=2,\n",
    "                init_steps=1, \n",
    "                final_tstep=5001, \n",
    "                seed=8634132, \n",
    "                device=\"cuda\", \n",
    "                weight_file=weight_file)\n",
    "print(\"MAE mean: {:1.3f}, std: {:1.3f}\".format(np.mean(errs), np.std(errs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('chnet': virtualenv)",
   "language": "python",
   "name": "python37464bitchnetvirtualenvdb68832a8f03482684037479c9d5262c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

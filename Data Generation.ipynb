{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "# from chnet.cahn_hill import ch_run_torch\n",
    "from toolz.curried import pipe, curry, compose, memoize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memReport():\n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj):\n",
    "            print(type(obj), obj.size())\n",
    "    \n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "        \n",
    "def get_free_gpu():\n",
    "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
    "    memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "    return np.argmax(memory_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = curry(np.fft.fft)\n",
    "ifft = curry(np.fft.ifft)\n",
    "fftn = curry(np.fft.fftn)\n",
    "ifftn = curry(np.fft.ifftn)\n",
    "fftshift = curry(np.fft.fftshift)\n",
    "ifftshift = curry(np.fft.ifftshift)\n",
    "torch_rfft = curry(torch.rfft)\n",
    "torch_irfft = curry(torch.irfft)\n",
    "\n",
    "def conjugate(x):\n",
    "    y = torch.empty_like(x)\n",
    "    y[..., 1] = x[..., 1] * -1\n",
    "    y[..., 0] = x[... , 0]\n",
    "    return y\n",
    "\n",
    "@curry\n",
    "def mult(x1, x2):\n",
    "    y = torch.empty_like(x1)\n",
    "    y[..., 0] = x1[..., 0]*x2[..., 0] - x1[..., 1]*x2[..., 1]\n",
    "    y[..., 1] = x1[..., 0]*x2[..., 1] + x1[..., 1]*x2[..., 0]\n",
    "    return y\n",
    "\n",
    "@curry\n",
    "def imfilter_real(f_data1, f_data2):\n",
    "    \"\"\"\n",
    "    For convolving f_data1 with f_data2 using PyTorch\n",
    "    \"\"\"\n",
    "    ndim = 2\n",
    "    f_data1 = torch.from_numpy(f_data1).double()\n",
    "    f_data2 = torch.from_numpy(f_data2).double()\n",
    "    rfft = torch_rfft(signal_ndim=ndim)\n",
    "    irfft = torch_irfft(signal_ndim=ndim)\n",
    "    return pipe(f_data1,\n",
    "                rfft,\n",
    "                lambda x: mult(x, conjugate(rfft(f_data2))),\n",
    "                irfft,\n",
    "                fftshift)\n",
    "\n",
    "@curry\n",
    "def imfilter(x_data1, x_data2):\n",
    "    \"\"\"\n",
    "    For convolving f_data1 with f_data2 using PyTorch\n",
    "    \"\"\"\n",
    "    ndim = 2\n",
    "    f_data1 = np.zeros(list(x_data1.shape)+[2,])\n",
    "    f_data2 = np.zeros(list(x_data2.shape)+[2,])\n",
    "    f_data1[...,0] = x_data1\n",
    "    f_data2[...,0] = x_data2\n",
    "    f_data1 = torch.from_numpy(f_data1).double()\n",
    "    f_data2 = torch.from_numpy(f_data2).double()\n",
    "    fft = curry(torch.fft)(signal_ndim=ndim)\n",
    "    ifft = curry(torch.ifft)(signal_ndim=ndim)\n",
    "    return pipe(f_data1,\n",
    "                fft,\n",
    "                lambda x: mult(x, conjugate(fft(f_data2))),\n",
    "                ifft,\n",
    "                lambda x: x[...,0],\n",
    "                fftshift)\n",
    "\n",
    "def ch_run_torch(x_data, args):\n",
    "\n",
    "    N = x_data.shape[1]\n",
    "    if not np.all(np.array(x_data.shape[1:]) == N):\n",
    "        raise RuntimeError(\"x_data must represent a square domain\")\n",
    "\n",
    "    L = args.dx * N\n",
    "    k = np.arange(N)\n",
    "\n",
    "    if N % 2 == 0:\n",
    "        N1 = N // 2\n",
    "        N2 = N1\n",
    "    else:\n",
    "        N1 = (N - 1) // 2\n",
    "        N2 = N1 + 1\n",
    "\n",
    "    k[N2:] = (k - N1)[:N1]\n",
    "    k = k * 2 * np.pi / L\n",
    "\n",
    "    i_ = np.indices(x_data.shape[1:])\n",
    "\n",
    "    ksq = np.zeros((1, N, N, 2))\n",
    "\n",
    "    ksq[...,0] = np.sum(k[i_] ** 2, axis=0)[None]\n",
    "    ksq[...,1] = np.sum(k[i_] ** 2, axis=0)[None]\n",
    "\n",
    "    ksq = torch.from_numpy(ksq).double().to(args.device)\n",
    "\n",
    "    a1 = 3.\n",
    "    a2 = 0.\n",
    "\n",
    "    explicit = ksq * (a1 - args.gamma * a2 * ksq)\n",
    "    implicit = ksq * ((1 - a1) - args.gamma * (1 - a2) * ksq)\n",
    "\n",
    "    ndim = 2\n",
    "    fft  = curry(torch.fft)(signal_ndim=ndim)\n",
    "    ifft = curry(torch.ifft)(signal_ndim=ndim)\n",
    "\n",
    "    response = torch.zeros(list(x_data.shape)+[2,], dtype=torch.double, device=args.device)\n",
    "    response[...,0] = x_data\n",
    "    Fy = fft(response)\n",
    "\n",
    "    for i in range(args.sim_steps):\n",
    "        FX  = Fy\n",
    "        FX3 = fft(response ** 3)\n",
    "        Fy  = (FX * (1 + args.dt * explicit) - ksq * args.dt * FX3) / (1 - args.dt * implicit)\n",
    "        response = ifft(Fy)\n",
    "#         del FX, FX3\n",
    "#         torch.cuda.empty_cache()\n",
    "    \n",
    "    del FX, FX3, Fy, ksq, explicit, implicit\n",
    "    torch.cuda.empty_cache()\n",
    "    return response[...,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_unif(nsamples, dim_x, dim_y,scale=0.1, seed=354875):\n",
    "    np.random.seed(seed)\n",
    "    return (2 * np.random.random((nsamples, dim_x, dim_y)) - 1) * scale\n",
    "\n",
    "\n",
    "def init_norm(nsamples, dim_x, dim_y, scale_mean=0.1, scale_std=0.1, seed=354875):\n",
    "    np.random.seed(seed)\n",
    "    means  = (2 * np.random.random(nsamples) - 1) * scale_mean\n",
    "    x_data = [np.random.normal(loc=m, scale=scale_std, size = (1, dim_x, dim_y)) for m in means]\n",
    "    x_data = np.concatenate(x_data, axis=0)\n",
    "    return x_data\n",
    "\n",
    "def get_fname(output_folder, indx, args):\n",
    "    return output_folder + \"/ch_%d_gamma_%d_dt_%d_dx_%d_%d_%s.npy\" % (indx*args.sim_steps, \n",
    "                                                                      int(args.gamma*1000), \n",
    "                                                                      int(args.dt*1000), \n",
    "                                                                      int(args.dx*1000), \n",
    "                                                                      args.dim_x, args.init)\n",
    "\n",
    "def generate(args, n_runs=100, output_folder=\"indata\"):\n",
    "\n",
    "    if args.init == \"unif\":\n",
    "        x_data = init_unif(args.nsamples, args.dim_x, args.dim_y, seed=354875)\n",
    "    elif args.init == \"norm\":\n",
    "        x_data = init_norm(args.nsamples, args.dim_x, args.dim_y, seed=784361)\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_data = torch.from_numpy(x_data).double().to(args.device)\n",
    "\n",
    "    np.save(get_fname(output_folder, 0, args), x_data)\n",
    "    \n",
    "    print(\"Starting Execution\")\n",
    "    for i in tqdm.tqdm_notebook(range(n_runs)):\n",
    "        \n",
    "        y_data = ch_run_torch(y_data,args)\n",
    "        fname = get_fname(output_folder, i+1, args)\n",
    "        np.save(fname, y_data.cpu().numpy())\n",
    "        \n",
    "    print(\"Ending Execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    nsamples=4096\n",
    "    dim_x=101\n",
    "    dim_y=dim_x\n",
    "    sim_steps=100\n",
    "    dx=0.25\n",
    "    dt=0.01\n",
    "    gamma=1.0\n",
    "    device=torch.device(\"cuda:0\")\n",
    "    init=\"norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Execution\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423f161a0fb54be78a13da538a219695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ending Execution\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "generate(args, output_folder=\"data/norm\", n_runs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    nsamples=4096\n",
    "    dim_x=101\n",
    "    dim_y=dim_x\n",
    "    sim_steps=100\n",
    "    dx=0.25\n",
    "    dt=0.01\n",
    "    gamma=1.0\n",
    "    device=torch.device(\"cuda:0\")\n",
    "    init=\"unif\"\n",
    "torch.cuda.empty_cache()\n",
    "generate(args, output_folder=\"data/unif\", n_runs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_im(im, title=None):\n",
    "    im = np.squeeze(im)\n",
    "    plt.imshow(im)\n",
    "    plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"data/unif/ch_10000_gamma_1000_dt_10_dx_250_101_unif.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Aug 13 2019, 20:35:49) \n",
      "[GCC 7.3.0]\n",
      "2.7\n",
      "svmem(total=404005154816, available=392542130176, percent=2.8, used=10063011840, free=390920663040, active=4617043968, inactive=958767104, buffers=40955904, cached=2980524032, shared=224067584, slab=1554169856)\n",
      "memory GB: 2.914287567138672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/hhive1/ashanker9/data/anaconda3/envs/chnet/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "cpuStats()\n",
    "memReport()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
